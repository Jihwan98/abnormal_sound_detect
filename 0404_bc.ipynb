{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d76e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, path, train=True, transform=None, sample_rate=16000):\n",
    "        self.path = path\n",
    "        if train:\n",
    "            self.normal_data_path = os.path.join(path, 'train/normal')\n",
    "            self.abnormal_data_path = os.path.join(path, 'train/abnormal')\n",
    "        else:\n",
    "            self.normal_data_path = os.path.join(path, 'test/normal')\n",
    "            self.abnormal_data_path = os.path.join(path, 'test/abnormal')\n",
    "        \n",
    "        self.normal_data_list = glob.glob(os.path.join(self.normal_data_path, '*.wav'))\n",
    "        self.abnormal_data_list = glob.glob(os.path.join(self.abnormal_data_path, '*.wav'))\n",
    "        self.data_list = self.normal_data_list + self.abnormal_data_list\n",
    "        self.label_list = [0]*len(self.normal_data_list) + [1]*len(self.abnormal_data_list)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.sr = sample_rate\n",
    "        self.frame_length = 0.025\n",
    "        self.frame_stride = 0.0126\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_path = self.data_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        data = self.log_Mel_S(data_path)\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        return data, label # (1, 40, 80)\n",
    "    \n",
    "    def log_Mel_S(self, wav_file):\n",
    "        y, sr = librosa.load(wav_file, sr=self.sr)\n",
    "        if len(y) < 16000:\n",
    "            y = np.pad(y, (0,16000 - len(y)))\n",
    "        elif len(y) > 16000:\n",
    "            y = y[:16000]\n",
    "        else:\n",
    "            y = y\n",
    "\n",
    "        input_nfft = int(round(sr * self.frame_length))\n",
    "        input_stride = int(round(sr * self.frame_stride))\n",
    "\n",
    "        s = librosa.feature.melspectrogram(y=y, n_mels=40, n_fft=input_nfft, hop_length=input_stride)\n",
    "        s = librosa.power_to_db(s, ref=np.max)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.__len__() : 45386\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioDataset(path='/mnt/storage1/위급상황 음성_음향/Training/bc_data', train=True)\n",
    "\n",
    "print(f'dataset.__len__() : {dataset.__len__()}')\n",
    "dataset_indices = list(range(dataset.__len__()))\n",
    "np.random.shuffle(dataset_indices)\n",
    "val_split_index = int(np.floor(0.2 * dataset.__len__()))\n",
    "train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=100, sampler=train_sampler, shuffle=False)\n",
    "val_loader = DataLoader(dataset=dataset, batch_size=100, sampler=val_sampler, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BC(nn.Module):\n",
    "    def __init__(self, input_channel=1):\n",
    "        super(BC, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 5 * 10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BC()\n",
    "if torch.cuda.is_available():\n",
    "    bc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BC(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): Linear(in_features=6400, out_features=512, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (16): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 40, 80]             320\n",
      "       BatchNorm2d-2           [-1, 32, 40, 80]              64\n",
      "              ReLU-3           [-1, 32, 40, 80]               0\n",
      "         MaxPool2d-4           [-1, 32, 20, 40]               0\n",
      "            Conv2d-5           [-1, 64, 20, 40]          18,496\n",
      "       BatchNorm2d-6           [-1, 64, 20, 40]             128\n",
      "              ReLU-7           [-1, 64, 20, 40]               0\n",
      "         MaxPool2d-8           [-1, 64, 10, 20]               0\n",
      "            Conv2d-9          [-1, 128, 10, 20]          73,856\n",
      "      BatchNorm2d-10          [-1, 128, 10, 20]             256\n",
      "             ReLU-11          [-1, 128, 10, 20]               0\n",
      "        MaxPool2d-12           [-1, 128, 5, 10]               0\n",
      "          Flatten-13                 [-1, 6400]               0\n",
      "           Linear-14                  [-1, 512]       3,277,312\n",
      "             ReLU-15                  [-1, 512]               0\n",
      "           Linear-16                    [-1, 1]             513\n",
      "          Sigmoid-17                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 3,370,945\n",
      "Trainable params: 3,370,945\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.50\n",
      "Params size (MB): 12.86\n",
      "Estimated Total Size (MB): 17.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(bc, (1, 40, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, optimizer, num_epochs, start_epoch=0, early_stopping=False):\n",
    "    train_loss_arr = []\n",
    "    train_acc_arr = []\n",
    "    test_loss_arr = []\n",
    "    test_acc_arr = []\n",
    "    \n",
    "    best_test_loss = 999999\n",
    "    early_stop, early_stop_max = 0, 3\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        epoch_loss = 0.\n",
    "        epoch_acc = 0.\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            train_x, train_y = data[0].cuda(), data[1].cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            model.train()\n",
    "            outputs = model(train_x)\n",
    "            y_pred = torch.round(outputs)\n",
    "            batch_acc = ( (y_pred == train_y.unsqueeze(1)).sum() / train_y.shape[0] ) * 100\n",
    "            epoch_acc += batch_acc.item()\n",
    "\n",
    "            train_loss = loss(outputs.float(), train_y.unsqueeze(1).float())\n",
    "            epoch_loss += train_loss.item()\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch : {epoch + 1} [{batch_idx * len(train_x)}/{len(train_idx)}({100 * 100. * batch_idx/len(train_idx) :.2f}%)]'\\\n",
    "                    +f'\\tLoss : {train_loss.item() / len(train_x) :.4f}, Accuracy : {batch_acc}%')\n",
    "        \n",
    "        train_acc_arr.append((epoch_acc / len(train_idx)))\n",
    "        train_loss_arr.append((epoch_loss / len(train_idx)))\n",
    "\n",
    "        # validation\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        test_acc = 0.\n",
    "        for test_x, test_y in val_loader:\n",
    "            test_x = test_x.cuda()\n",
    "            test_y = test_y.cuda()\n",
    "\n",
    "            outputs = model(test_x)\n",
    "            y_pred = torch.round(outputs)\n",
    "            acc = ( (y_pred == test_y.unsqueeze(1)).sum() / test_y.shape[0] ) * 100\n",
    "            test_acc += acc.item()\n",
    "\n",
    "            batch_loss = loss(outputs.float(), test_y.unsqueeze(1).float())\n",
    "            test_loss += batch_loss.item()\n",
    "\n",
    "        test_acc_arr.append((test_acc / len(val_idx)))\n",
    "        test_loss_arr.append((test_loss / len(val_idx)))\n",
    "\n",
    "        if early_stopping:\n",
    "            if best_test_loss > test_loss:\n",
    "                best_test_loss = test_loss\n",
    "                early_stop = 0\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Average Train Loss : {train_loss_arr[epoch-start_epoch] :.4f}, ' +\\\n",
    "                f'Average Test Loss : {test_loss_arr[epoch-start_epoch] :.4f}, Average Train Accuracy : {train_acc_arr[epoch-start_epoch] :.4f}, ' +\\\n",
    "                f'Average Test Accuracy : {test_acc_arr[epoch-start_epoch] :.4f}\\n')\n",
    "            else:\n",
    "                early_stop += 1\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Average Train Loss : {train_loss_arr[epoch-start_epoch] :.4f}, ' +\\\n",
    "                f'Average Test Loss : {test_loss_arr[epoch-start_epoch] :.4f}, Average Train Accuracy : {train_acc_arr[epoch-start_epoch] :.4f}, ' +\\\n",
    "                f'Average Test Accuracy : {test_acc_arr[epoch-start_epoch] :.4f}\\n')\n",
    "\n",
    "            if early_stop >= early_stop_max:\n",
    "                break\n",
    "        else:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Average Train Loss : {train_loss_arr[epoch-start_epoch] :.4f}, ' +\\\n",
    "            f'Average Test Loss : {test_loss_arr[epoch-start_epoch] :.4f}, Average Train Accuracy : {train_acc_arr[epoch-start_epoch] :.4f}, ' +\\\n",
    "            f'Average Test Accuracy : {test_acc_arr[epoch-start_epoch] :.4f}\\n')\n",
    "    return train_acc_arr, train_loss_arr, test_acc_arr, test_loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 [0/36309(0.00%)]\tLoss : 0.0078, Accuracy : 29.0%\n",
      "Epoch : 1 [1000/36309(2.75%)]\tLoss : 0.0009, Accuracy : 97.0%\n",
      "Epoch : 1 [2000/36309(5.51%)]\tLoss : 0.0005, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [3000/36309(8.26%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch : 1 [4000/36309(11.02%)]\tLoss : 0.0003, Accuracy : 97.99999237060547%\n",
      "Epoch : 1 [5000/36309(13.77%)]\tLoss : 0.0002, Accuracy : 100.0%\n",
      "Epoch : 1 [6000/36309(16.52%)]\tLoss : 0.0007, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [7000/36309(19.28%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [9000/36309(24.79%)]\tLoss : 0.0003, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [11000/36309(30.30%)]\tLoss : 0.0002, Accuracy : 100.0%\n",
      "Epoch : 1 [12000/36309(33.05%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch : 1 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [15000/36309(41.31%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [19000/36309(52.33%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [20000/36309(55.08%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [22000/36309(60.59%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 1 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 1 [36000/36309(99.15%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch [1/50], Average Train Loss : 0.0004, Average Test Loss : 0.0001, Average Train Accuracy : 0.9943, Average Test Accuracy : 1.0018\n",
      "\n",
      "Epoch : 2 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [1000/36309(2.75%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 2 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [9000/36309(24.79%)]\tLoss : 0.0002, Accuracy : 97.99999237060547%\n",
      "Epoch : 2 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [13000/36309(35.80%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 2 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [32000/36309(88.13%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 2 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 2 [35000/36309(96.39%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch : 2 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [2/50], Average Train Loss : 0.0002, Average Test Loss : 0.0012, Average Train Accuracy : 1.0009, Average Test Accuracy : 0.9993\n",
      "\n",
      "Epoch : 3 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [9000/36309(24.79%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 3 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [13000/36309(35.80%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 3 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [17000/36309(46.82%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch : 3 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [23000/36309(63.35%)]\tLoss : 0.0006, Accuracy : 98.99999237060547%\n",
      "Epoch : 3 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [25000/36309(68.85%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 3 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [27000/36309(74.36%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 3 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [30000/36309(82.62%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch : 3 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 3 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [3/50], Average Train Loss : 0.0006, Average Test Loss : 0.0001, Average Train Accuracy : 1.0007, Average Test Accuracy : 1.0017\n",
      "\n",
      "Epoch : 4 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [2000/36309(5.51%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch : 4 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [8000/36309(22.03%)]\tLoss : 0.0100, Accuracy : 98.99999237060547%\n",
      "Epoch : 4 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [19000/36309(52.33%)]\tLoss : 0.0004, Accuracy : 98.99999237060547%\n",
      "Epoch : 4 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 4 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [4/50], Average Train Loss : 0.0001, Average Test Loss : 0.0000, Average Train Accuracy : 1.0015, Average Test Accuracy : 1.0018\n",
      "\n",
      "Epoch : 5 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [5000/36309(13.77%)]\tLoss : 0.0004, Accuracy : 98.99999237060547%\n",
      "Epoch : 5 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [14000/36309(38.56%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 5 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [23000/36309(63.35%)]\tLoss : 0.0003, Accuracy : 98.99999237060547%\n",
      "Epoch : 5 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [30000/36309(82.62%)]\tLoss : 0.0004, Accuracy : 98.99999237060547%\n",
      "Epoch : 5 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 5 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [5/50], Average Train Loss : 0.0000, Average Test Loss : 0.0000, Average Train Accuracy : 1.0018, Average Test Accuracy : 1.0019\n",
      "\n",
      "Epoch : 6 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [11000/36309(30.30%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 6 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [23000/36309(63.35%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 6 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 6 [36000/36309(99.15%)]\tLoss : 0.0001, Accuracy : 100.0%\n",
      "Epoch [6/50], Average Train Loss : 0.0000, Average Test Loss : 0.0004, Average Train Accuracy : 1.0021, Average Test Accuracy : 1.0017\n",
      "\n",
      "Epoch : 7 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [15000/36309(41.31%)]\tLoss : 0.0012, Accuracy : 98.99999237060547%\n",
      "Epoch : 7 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [19000/36309(52.33%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 7 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [33000/36309(90.89%)]\tLoss : 0.0003, Accuracy : 98.99999237060547%\n",
      "Epoch : 7 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 7 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [7/50], Average Train Loss : 0.0001, Average Test Loss : 0.0000, Average Train Accuracy : 1.0015, Average Test Accuracy : 1.0018\n",
      "\n",
      "Epoch : 8 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [31000/36309(85.38%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 8 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 8 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [8/50], Average Train Loss : 0.0000, Average Test Loss : 0.0000, Average Train Accuracy : 1.0022, Average Test Accuracy : 1.0019\n",
      "\n",
      "Epoch : 9 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [25000/36309(68.85%)]\tLoss : 0.0007, Accuracy : 98.99999237060547%\n",
      "Epoch : 9 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 9 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [9/50], Average Train Loss : 0.0000, Average Test Loss : 0.0000, Average Train Accuracy : 1.0023, Average Test Accuracy : 1.0022\n",
      "\n",
      "Epoch : 10 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [24000/36309(66.10%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 10 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [31000/36309(85.38%)]\tLoss : 0.0001, Accuracy : 98.99999237060547%\n",
      "Epoch : 10 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 10 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [10/50], Average Train Loss : 0.0000, Average Test Loss : 0.0002, Average Train Accuracy : 1.0023, Average Test Accuracy : 1.0020\n",
      "\n",
      "Epoch : 11 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [10000/36309(27.54%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [14000/36309(38.56%)]\tLoss : 0.0002, Accuracy : 98.99999237060547%\n",
      "Epoch : 11 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [18000/36309(49.57%)]\tLoss : 0.0100, Accuracy : 98.99999237060547%\n",
      "Epoch : 11 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [20000/36309(55.08%)]\tLoss : 0.0013, Accuracy : 97.99999237060547%\n",
      "Epoch : 11 [21000/36309(57.84%)]\tLoss : 0.0003, Accuracy : 98.99999237060547%\n",
      "Epoch : 11 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 11 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [11/50], Average Train Loss : 0.0002, Average Test Loss : 0.0004, Average Train Accuracy : 1.0016, Average Test Accuracy : 1.0015\n",
      "\n",
      "Epoch : 12 [0/36309(0.00%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [1000/36309(2.75%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [2000/36309(5.51%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [3000/36309(8.26%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [4000/36309(11.02%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [5000/36309(13.77%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [6000/36309(16.52%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [7000/36309(19.28%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [8000/36309(22.03%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [9000/36309(24.79%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [10000/36309(27.54%)]\tLoss : 0.0005, Accuracy : 98.99999237060547%\n",
      "Epoch : 12 [11000/36309(30.30%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [12000/36309(33.05%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [13000/36309(35.80%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [14000/36309(38.56%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [15000/36309(41.31%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [16000/36309(44.07%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [17000/36309(46.82%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [18000/36309(49.57%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [19000/36309(52.33%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [20000/36309(55.08%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [21000/36309(57.84%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [22000/36309(60.59%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [23000/36309(63.35%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [24000/36309(66.10%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [25000/36309(68.85%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [26000/36309(71.61%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [27000/36309(74.36%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [28000/36309(77.12%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [29000/36309(79.87%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [30000/36309(82.62%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [31000/36309(85.38%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [32000/36309(88.13%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [33000/36309(90.89%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [34000/36309(93.64%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [35000/36309(96.39%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch : 12 [36000/36309(99.15%)]\tLoss : 0.0000, Accuracy : 100.0%\n",
      "Epoch [12/50], Average Train Loss : 0.0000, Average Test Loss : 0.0001, Average Train Accuracy : 1.0019, Average Test Accuracy : 1.0018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bc_loss = nn.BCELoss()\n",
    "bc_optimizer = optim.Adam(bc.parameters())\n",
    "avg_train_acc, avg_train_loss, avg_test_acc, avg_test_loss = train(bc, bc_loss, bc_optimizer, 50, start_epoch=0, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(avg_train_loss, label='train')\n",
    "plt.plot(avg_test_loss, label='test')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(avg_train_acc, label='train')\n",
    "plt.plot(avg_test_acc, label='test')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bc.state_dict(), 'model/bc_0404.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_Mel_S(wav_file):\n",
    "    sr = 16000\n",
    "    frame_length = 0.025\n",
    "    frame_stride = 0.0126 \n",
    "    y, sr = librosa.load(wav_file, sr=sr)\n",
    "    if len(y) < 16000:\n",
    "        y = np.pad(y, (0,16000 - len(y)))\n",
    "    elif len(y) > 16000:\n",
    "        y = y[:16000]\n",
    "    else:\n",
    "        y = y\n",
    "\n",
    "    input_nfft = int(round(sr * frame_length))\n",
    "    input_stride = int(round(sr * frame_stride))\n",
    "\n",
    "    s = librosa.feature.melspectrogram(y=y, n_mels=40, n_fft=input_nfft, hop_length=input_stride)\n",
    "    s = librosa.power_to_db(s, ref=np.max)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.eval()\n",
    "data_path = 'data/원천데이터/abnormal_1s/가스사고_512992_label_1.wav'\n",
    "s = log_Mel_S(data_path)\n",
    "out = bc(torch.Tensor(s.reshape(1,1,40,80)).cuda())\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6489e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/원천데이터/normal_1s/실내_673584_label_0.wav'\n",
    "s = log_Mel_S(data_path)\n",
    "out = bc(torch.Tensor(s.reshape(1,1,40,80)).cuda())\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = glob.glob('/mnt/storage1/위급상황 음성_음향/Training/abnormal_1s_high/*.wav')\n",
    "abnormal_pred_list = []\n",
    "for i in data_list:\n",
    "    s = log_Mel_S(i)\n",
    "    out = bc(torch.Tensor(s.reshape(1,1,40,80)).cuda())\n",
    "    pred = torch.round(out).item()\n",
    "    abnormal_pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(abnormal_pred_list) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = glob.glob('/mnt/storage1/위급상황 음성_음향/Training/low_16_1s/*.wav')\n",
    "normal_pred_list = []\n",
    "for i in data_list:\n",
    "    s = log_Mel_S(i)\n",
    "    out = bc(torch.Tensor(s.reshape(1,1,40,80)).cuda())\n",
    "    pred = torch.round(out).item()\n",
    "    normal_pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(normal_pred_list) == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Predict               \n",
      "             Normal    Abnormal  \n",
      "Normal       23858          5\n",
      "Abnormal        15      32853\n"
     ]
    }
   ],
   "source": [
    "TN = (np.array(abnormal_pred_list) == 1).sum()\n",
    "FP = (np.array(abnormal_pred_list) == 0).sum()\n",
    "TP = (np.array(normal_pred_list) == 0).sum()\n",
    "FN = (np.array(normal_pred_list) == 1).sum()\n",
    "\n",
    "print(f\"{' '*15}Predict{' '*15}\")\n",
    "print(f\"{' '*13}{'Normal':10s}{'Abnormal':10s}\")\n",
    "print(f\"Normal  {TP:10d}{FN:11d}\")\n",
    "print(f\"Abnormal{FP:10d}{TN:11d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f625d1f143474bbd97fe34f158cee8f42e73fd18755d10f5b95b794645d1ccd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
