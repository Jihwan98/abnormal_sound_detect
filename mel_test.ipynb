{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece64e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659bc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, path, transform=None, sample_rate=16000):\n",
    "        self.path = path\n",
    "        self.data_list = glob.glob(self.path + '/*.wav')\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.sr = sample_rate\n",
    "        self.frame_length = 0.025 # win_length, 자연어 처리 분야에서 25ms 크기를 기본으로 하고 있음 (16000Hz -> 400)\n",
    "        self.frame_stride = 0.0126 # hop_length, 일반적으로 10ms의 크기를 기본으로 하고 있음 (16000Hz -> 160)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_path = self.data_list[idx]\n",
    "        data = self.normalize(self.Mel_S(data_path))\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data # (1, 40, 80)\n",
    "    \n",
    "    def Mel_S(self, wav_file):\n",
    "        y, sr = librosa.load(wav_file, sr=self.sr)\n",
    "    \n",
    "        input_nfft = int(round(sr*self.frame_length))\n",
    "        input_stride = int(round(sr*self.frame_stride))\n",
    "\n",
    "        s = librosa.feature.melspectrogram(y=y, n_mels=40, n_fft=input_nfft, hop_length=input_stride)\n",
    "#         print(f\"Wav lenght : {len(y)/sr}, Mes_S shape : {np.shape(S)}\")\n",
    "        \n",
    "        return s\n",
    "    \n",
    "    def normalize(self, s):\n",
    "        s = (s - s.mean()) / s.std() # standardization\n",
    "        s = (s - s.min()) / (s.max() - s.min()) # min max normalization\n",
    "        \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b973111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_channel=1, h_dim=128*5*10, z_dim=512):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (128, 5, 10)),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def reparameterization(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std*eps # return z sample\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, log_var = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterization(mu, log_var)\n",
    "        return z, mu, log_var\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, log_var = self.bottleneck(h)\n",
    "        return z, mu, log_var\n",
    "    \n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z, mu, log_var = self.encode(x)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, log_var\n",
    "\n",
    "model = VAE()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4457473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model/vae_mel_200.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2eda522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 40, 80]             320\n",
      "              ReLU-2           [-1, 32, 40, 80]               0\n",
      "         MaxPool2d-3           [-1, 32, 20, 40]               0\n",
      "            Conv2d-4           [-1, 64, 20, 40]          18,496\n",
      "              ReLU-5           [-1, 64, 20, 40]               0\n",
      "         MaxPool2d-6           [-1, 64, 10, 20]               0\n",
      "            Conv2d-7          [-1, 128, 10, 20]          73,856\n",
      "              ReLU-8          [-1, 128, 10, 20]               0\n",
      "         MaxPool2d-9           [-1, 128, 5, 10]               0\n",
      "          Flatten-10                 [-1, 6400]               0\n",
      "           Linear-11                  [-1, 512]       3,277,312\n",
      "           Linear-12                  [-1, 512]       3,277,312\n",
      "           Linear-13                 [-1, 6400]       3,283,200\n",
      "        Unflatten-14           [-1, 128, 5, 10]               0\n",
      "  ConvTranspose2d-15           [-1, 64, 10, 20]         131,136\n",
      "             ReLU-16           [-1, 64, 10, 20]               0\n",
      "  ConvTranspose2d-17           [-1, 32, 20, 40]          32,800\n",
      "             ReLU-18           [-1, 32, 20, 40]               0\n",
      "  ConvTranspose2d-19            [-1, 1, 40, 80]             513\n",
      "          Sigmoid-20            [-1, 1, 40, 80]               0\n",
      "================================================================\n",
      "Total params: 10,094,945\n",
      "Trainable params: 10,094,945\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.87\n",
      "Params size (MB): 38.51\n",
      "Estimated Total Size (MB): 42.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 40, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b54962",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = AudioDataset(path='data/원천데이터/normal_1s')\n",
    "abnormal_dataset = AudioDataset(path='data/원천데이터/abnormal_1s')\n",
    "\n",
    "normal_loader = DataLoader(dataset=normal_dataset, batch_size=1, shuffle=False)\n",
    "abnormal_loader = DataLoader(dataset=abnormal_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63c8b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, log_var):\n",
    "#     KLD = -0.5*torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "\n",
    "    return BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45812c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2.96%--5.93%--8.89%--11.85%--14.81%--17.78%--20.74%--23.70%--26.67%--29.63%--32.59%--35.56%--38.52%--41.48%--44.44%--47.41%--50.37%--53.33%--56.30%--59.26%--62.22%--65.19%--68.15%--71.11%--74.07%--77.04%--80.00%--82.96%--85.93%--88.89%--91.85%--94.81%--97.78%--100% \n",
      " done\n"
     ]
    }
   ],
   "source": [
    "normal_loss = []\n",
    "model.eval()\n",
    "for idx, normal_data in enumerate(normal_loader):\n",
    "    normal_data = normal_data.cuda()\n",
    "    recon, mu, log_var = model(normal_data)\n",
    "    loss = loss_function(recon, normal_data, mu, log_var)\n",
    "    normal_loss.append(loss.item())\n",
    "    if (idx+1) % 100 == 0:\n",
    "        print(f'--{((idx+1) / normal_loader.__len__()) * 100 :0.2f}%', end='')\n",
    "print(\"--100% \\n done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474c4cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_246858/2597958812.py:36: RuntimeWarning: invalid value encountered in true_divide\n",
      "  s = (s - s.mean()) / s.std() # standardization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--3.46%--6.91%--10.37%--13.82%--17.28%--20.73%--24.19%--27.64%--31.10%--34.55%--38.01%--41.47%--44.92%--48.38%--51.83%--55.29%--58.74%--62.20%--65.65%--69.11%--72.56%--76.02%--79.47%--82.93%--86.39%--89.84%--93.30%--96.75%--100% \n",
      " done\n"
     ]
    }
   ],
   "source": [
    "abnormal_loss = []\n",
    "model.eval()\n",
    "for idx, abnormal_data in enumerate(abnormal_loader):\n",
    "    abnormal_data = abnormal_data.cuda()\n",
    "    recon, mu, log_var = model(abnormal_data)\n",
    "    loss = loss_function(recon, abnormal_data, mu, log_var)\n",
    "    abnormal_loss.append(loss.item())\n",
    "    if (idx+1) % 100 == 0:\n",
    "        print(f'--{((idx+1) / abnormal_loader.__len__()) * 100 :0.2f}%', end='')\n",
    "print(\"--100% \\n done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "887f29e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.hist(normal_loss, color='r', alpha=0.5, bins=100, label='normal')\n",
    "plt.hist(abnormal_loss, color='b', alpha=0.5, bins=100, label='abnormal')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd126f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
